{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# 将src目录添加到系统路径中\n",
    "sys.path.append('../')\n",
    "\n",
    "# 导入本地模块\n",
    "#from src.timellm import TimeLLM\n",
    "from src.baselines import TimeLLM \n",
    "from src.baselines import PatchTST\n",
    "from data_provider.data_factory import data_provider\n",
    "from utils.tools import *\n",
    "\n",
    "# 导入第三方库\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "#import tqdm\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "from accelerate import Accelerator, DeepSpeedPlugin\n",
    "from accelerate import DistributedDataParallelKwargs\n",
    "\n",
    "os.environ['CURL_CA_BUNDLE'] = ''\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"max_split_size_mb:64\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据相关参数\n",
    "DATA_NAME = 'electricity/electricity.csv'\n",
    "DESCRIPTION_PATH = '../dataset/prompt_bank/ECL.txt'\n",
    "DATA_PATH = Path('../dataset') / DATA_NAME\n",
    "\n",
    "# 模型相关参数\n",
    "TARGET_COL = 'OT'       # 目标列，代表电力需求\n",
    "NUM_EPOCHS = 3         # 训练轮数\n",
    "LEARNING_RATE = 1e-4    # 学习率\n",
    "DEVICE = 'cuda:1'\n",
    "\n",
    "# 加载描述文本\n",
    "try:\n",
    "    with open('../dataset/prompt_bank/ECL.txt', 'r', encoding='utf-8') as f:\n",
    "        description = f.read().strip()\n",
    "except FileNotFoundError:\n",
    "    print(\"Failed to find ECL.txt.\")\n",
    "    description = \"\"\n",
    "\n",
    "class Configs:\n",
    "    def __init__(self, task_name='long_term_forecast', \n",
    "                 pred_len=96, seq_len=96, d_ff=16,devices=\"1,2,3\",use_multi_gpu=True,\n",
    "                 d_model=8, patch_len=16, stride=8, llm_model='GPT2',\n",
    "                 llm_layers=6, prompt_domain=0, content=description,\n",
    "                 dropout=0.1, enc_in=7, dec_in=7, c_out=7, n_heads=3,\n",
    "                 llm_dim=768,data='custom', train_epochs=NUM_EPOCHS, root_path=\"../dataset/\", data_path=DATA_NAME,\n",
    "                 embed='timeF',batch_size=32, freq='h', label_len=48, features='M',\n",
    "                 target=TARGET_COL, seasonal_patterns='Monthly', augmentation_ratio=0,\n",
    "                 num_workers=3, patience=3, output_attention=False, use_amp=False, **kwconfig):\n",
    "        self.task_name = task_name\n",
    "        self.pred_len = pred_len\n",
    "        self.seq_len = seq_len\n",
    "        self.d_ff = d_ff\n",
    "        self.d_model = d_model\n",
    "        self.patch_len = patch_len\n",
    "        self.stride = stride\n",
    "        self.llm_model = llm_model\n",
    "        self.llm_layers = llm_layers\n",
    "        self.prompt_domain = prompt_domain\n",
    "        self.content = content\n",
    "        self.dropout = dropout\n",
    "        self.enc_in = enc_in\n",
    "        self.dec_in = dec_in\n",
    "        self.c_out = c_out\n",
    "        self.n_heads = n_heads\n",
    "        self.llm_dim = llm_dim\n",
    "        self.data = data\n",
    "        self.root_path = root_path\n",
    "        self.data_path = data_path\n",
    "        self.embed = embed\n",
    "        self.batch_size = batch_size\n",
    "        self.freq = freq\n",
    "        self.label_len = label_len\n",
    "        self.features = features\n",
    "        self.target = target\n",
    "        self.seasonal_patterns = seasonal_patterns\n",
    "        self.augmentation_ratio = augmentation_ratio\n",
    "        self.num_workers = num_workers\n",
    "        self.patience = patience\n",
    "        self.output_attention = output_attention\n",
    "        self.use_amp = use_amp\n",
    "        self.devices = devices\n",
    "        self.use_multi_gpu = use_multi_gpu  \n",
    "        self.train_epochs = train_epochs     \n",
    "        self.__dict__.update(kwconfig)\n",
    "\n",
    "config = Configs()\n",
    "config.use_gpu = True if torch.cuda.is_available() else False\n",
    "\n",
    "if config.use_gpu and config.use_multi_gpu:\n",
    "    config.devices = config.devices.replace(' ', '')\n",
    "    device_ids = config.devices.split(',')\n",
    "    config.device_ids = [int(id_) for id_ in device_ids]\n",
    "    config.gpu = config.device_ids[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载数据集，解析 'date' 列为日期格式，并设置为索引\n",
    "try:\n",
    "    data = pd.read_csv(DATA_PATH, parse_dates=['date'], index_col='date')\n",
    "    print(data.head())\n",
    "except FileNotFoundError:\n",
    "    print(f\"Failed to find {DATA_PATH}.\")\n",
    "    data = pd.DataFrame()\n",
    "\n",
    "# 检查必要的列是否存在\n",
    "if TARGET_COL not in data.columns:\n",
    "    raise ValueError(f\"Not found '{TARGET_COL}' in the dataset. Please check.\")\n",
    "\n",
    "# 数据标准化\n",
    "scaler = StandardScaler()\n",
    "feature_cols = ['OT']  # 根据需要添加更多特征列\n",
    "scaled_data = scaler.fit_transform(data[feature_cols].values)\n",
    "scaled_data = pd.DataFrame(scaled_data, index=data.index, columns=feature_cols)\n",
    "\n",
    "print(scaled_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 提取最后 SEQ_LEN 个时间步的数据\n",
    "time_series_data = scaled_data[-config.seq_len:]\n",
    "\n",
    "# 转换为张量\n",
    "time_series_tensor = torch.tensor(time_series_data.values, dtype=torch.float32).to(DEVICE)\n",
    "\n",
    "print(\"Standarded Time series data shape: \", time_series_tensor.shape)\n",
    "\n",
    "# 绘制前5个特征的时间序列\n",
    "plt.figure(figsize=(12, 6))\n",
    "for i, col in enumerate(feature_cols[:5]):\n",
    "    plt.plot(time_series_data.index, time_series_data[col], label=col)\n",
    "plt.title(\"Time series data\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Standardized value\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_windows(data, target_col, seq_len, horizon):\n",
    "    \"\"\"\n",
    "    使用滑动窗口方法创建输入和目标数据。\n",
    "    \n",
    "    参数:\n",
    "    - data (DataFrame): 输入数据\n",
    "    - target_col (str): 目标列名\n",
    "    - seq_len (int): 输入序列长度\n",
    "    - horizon (int): 预测步数\n",
    "    \n",
    "    返回:\n",
    "    - X (ndarray): 输入特征\n",
    "    - y (ndarray): 目标值\n",
    "    \"\"\"\n",
    "    X = []\n",
    "    y = []\n",
    "    for i in range(len(data) - seq_len - horizon + 1):\n",
    "        X.append(data.iloc[i:i+seq_len].values)\n",
    "        y.append(data.iloc[i+seq_len:i+seq_len+horizon][target_col].values)\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "# 创建滑动窗口\n",
    "X, y = create_windows(scaled_data, TARGET_COL, config.seq_len, config.pred_len)\n",
    "print(\"滑动窗口后的 X 形状:\", X.shape)  # [样本数, SEQ_LEN, 特征数]\n",
    "print(\"滑动窗口后的 y 形状:\", y.shape)  # [样本数, HORIZON]\n",
    "\n",
    "# 分割训练集和测试集\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, shuffle=False\n",
    ")\n",
    "\n",
    "print(\"训练集形状:\", X_train.shape, y_train.shape)\n",
    "print(\"测试集形状:\", X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 选择一个批次进行测试\n",
    "sample_time_series = X_train[:config.batch_size]\n",
    "sample_time_series_tensor = torch.tensor(sample_time_series, dtype=torch.float32).to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义预测层\n",
    "prediction_layer = nn.Linear(config.d_model, 1).to(DEVICE)  # 单变量预测\n",
    "\n",
    "# 实例化 TimeLLM 模块\n",
    "#time_llm = TimeLLM.Model(config).float().to(DEVICE)\n",
    "model = TimeLLM.Model(config).float().to(DEVICE)\n",
    "print(\"TimeLLM 模块已实例化。\")\n",
    "\n",
    "# class TimeSeriesPredictor(nn.Module):\n",
    "#     \"\"\"\n",
    "#     时间序列预测器模型，结合 TimeLLM 模块和预测层。\n",
    "#     \"\"\"\n",
    "#     def __init__(self, time_llm, prediction_layer):\n",
    "#         super(TimeSeriesPredictor, self).__init__()\n",
    "#         self.time_llm = time_llm\n",
    "#         self.prediction_layer = prediction_layer\n",
    "    \n",
    "#     def forward(self, time_series_data, description, pred_len, seq_len):\n",
    "#         \"\"\"\n",
    "#         前向传播函数。\n",
    "        \n",
    "#         参数:\n",
    "#         - time_series_data (Tensor): 输入的时间序列数据，形状 [B, L, D]\n",
    "#         - description (str): 描述文本\n",
    "#         - pred_len (int): 预测步数\n",
    "#         - seq_len (int): 序列长度\n",
    "        \n",
    "#         返回:\n",
    "#         - predictions (Tensor): 预测结果，形状 [B, pred_len, 1]\n",
    "#         \"\"\"\n",
    "#         multi_modal_embedding, _ = self.time_llm(\n",
    "#             time_series_data, description, pred_len, seq_len\n",
    "#         )\n",
    "#         predictions = self.prediction_layer(multi_modal_embedding)\n",
    "#         return predictions\n",
    "\n",
    "# # 实例化完整模型\n",
    "# model = TimeSeriesPredictor(time_llm, prediction_layer).to(DEVICE)\n",
    "# model.train()\n",
    "# print(\"完整时间序列预测模型已实例化并切换到训练模式。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddp_kwconfig = DistributedDataParallelKwargs(find_unused_parameters=True)\n",
    "deepspeed_plugin = DeepSpeedPlugin(hf_ds_config='./ds_config_zero2.json')\n",
    "accelerator = Accelerator(kwargs_handlers=[ddp_kwconfig], deepspeed_plugin=deepspeed_plugin)\n",
    "\n",
    "train_data, train_loader = data_provider(config, 'train')\n",
    "vali_data, vali_loader = data_provider(config, 'val')\n",
    "test_data, test_loader = data_provider(config, 'test')\n",
    "# 定义损失函数和优化器\n",
    "criterion = nn.MSELoss()\n",
    "model_optim = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(model_optim, T_max=20, eta_min=1e-8)\n",
    "\n",
    "train_loader, vali_loader, test_loader, model, model_optim, scheduler = accelerator.prepare(train_loader, vali_loader, test_loader, model, model_optim, scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_steps = len(train_loader)\n",
    "early_stopping = EarlyStopping(accelerator=accelerator, patience=config.patience)\n",
    "mae_metric = nn.L1Loss()\n",
    "time_now = time.time()\n",
    "#if config.use_multi_gpu and config.use_gpu:\n",
    "#    model = nn.DataParallel(model, device_ids=config.device_ids)\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    iter_count = 0\n",
    "    train_loss = []\n",
    "\n",
    "    model.train()\n",
    "    epoch_time = time.time()\n",
    "    for i, (batch_x, batch_y, batch_x_mark, batch_y_mark) in tqdm(enumerate(train_loader)):\n",
    "        iter_count += 1\n",
    "        model_optim.zero_grad()\n",
    "\n",
    "        batch_x = batch_x.float().to(accelerator.device)\n",
    "        batch_y = batch_y.float().to(accelerator.device)\n",
    "        batch_x_mark = batch_x_mark.float().to(accelerator.device)\n",
    "        batch_y_mark = batch_y_mark.float().to(accelerator.device)\n",
    "\n",
    "        # decoder input\n",
    "        dec_inp = torch.zeros_like(batch_y[:, -config.pred_len:, :]).float().to(\n",
    "            accelerator.device)\n",
    "        dec_inp = torch.cat([batch_y[:, :config.label_len, :], dec_inp], dim=1).float().to(\n",
    "            accelerator.device)\n",
    "\n",
    "        # encoder - decoder\n",
    "        if config.use_amp:\n",
    "            with torch.cuda.amp.autocast():\n",
    "                if config.output_attention:\n",
    "                    outputs = model(batch_x, batch_x_mark, dec_inp, batch_y_mark)[0]\n",
    "                else:\n",
    "                    outputs = model(batch_x, batch_x_mark, dec_inp, batch_y_mark)\n",
    "\n",
    "                f_dim = -1 if config.features == 'MS' else 0\n",
    "                outputs = outputs[:, -config.pred_len:, f_dim:]\n",
    "                batch_y = batch_y[:, -config.pred_len:, f_dim:].to(accelerator.device)\n",
    "                loss = criterion(outputs, batch_y)\n",
    "                train_loss.append(loss.item())\n",
    "        else:\n",
    "            if config.output_attention:\n",
    "                outputs = model(batch_x, batch_x_mark, dec_inp, batch_y_mark)[0]\n",
    "            else:\n",
    "                outputs = model(batch_x, batch_x_mark, dec_inp, batch_y_mark)\n",
    "\n",
    "            f_dim = -1 if config.features == 'MS' else 0\n",
    "            outputs = outputs[:, -config.pred_len:, f_dim:]\n",
    "            batch_y = batch_y[:, -config.pred_len:, f_dim:]\n",
    "            loss = criterion(outputs, batch_y)\n",
    "            train_loss.append(loss.item())\n",
    "\n",
    "        if (i + 1) % 200 == 0:\n",
    "            accelerator.print(\n",
    "                \"\\titers: {0}, epoch: {1} | loss: {2:.7f}\".format(i + 1, epoch + 1, loss.item()))\n",
    "            speed = (time.time() - time_now) / iter_count\n",
    "            left_time = speed * ((config.train_epochs - epoch) * train_steps - i)\n",
    "            accelerator.print('\\tspeed: {:.4f}s/iter; left time: {:.4f}s'.format(speed, left_time))\n",
    "            iter_count = 0\n",
    "            time_now = time.time()\n",
    "\n",
    "        if config.use_amp:\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(model_optim)\n",
    "            scaler.update()\n",
    "        else:\n",
    "            accelerator.backward(loss)\n",
    "            model_optim.step()\n",
    "\n",
    "    accelerator.print(\"Epoch: {} cost time: {}\".format(epoch + 1, time.time() - epoch_time))\n",
    "    train_loss = np.average(train_loss)\n",
    "    vali_loss, vali_mae_loss = vali(config, accelerator, model, vali_data, vali_loader, criterion, mae_metric)\n",
    "    test_loss, test_mae_loss = vali(config, accelerator, model, test_data, test_loader, criterion, mae_metric)\n",
    "    accelerator.print(\n",
    "        \"Epoch: {0} | Train Loss: {1:.7f} Vali Loss: {2:.7f} Test Loss: {3:.7f} MAE Loss: {4:.7f}\".format(\n",
    "            epoch + 1, train_loss, vali_loss, test_loss, test_mae_loss))\n",
    "\n",
    "    path = os.path.join(accelerator.exp_dir, 'best.pth')\n",
    "    early_stopping(vali_loss, model, path)\n",
    "    if early_stopping.early_stop:\n",
    "        accelerator.print(\"Early stopping\")\n",
    "        break\n",
    "\n",
    "    if config.lradj != 'TST':\n",
    "        if config.lradj == 'COS':\n",
    "            scheduler.step()\n",
    "            accelerator.print(\"lr = {:.10f}\".format(model_optim.param_groups[0]['lr']))\n",
    "        else:\n",
    "            if epoch == 0:\n",
    "                config.learning_rate = model_optim.param_groups[0]['lr']\n",
    "                accelerator.print(\"lr = {:.10f}\".format(model_optim.param_groups[0]['lr']))\n",
    "            adjust_learning_rate(accelerator, model_optim, scheduler, epoch + 1, config, printout=True)\n",
    "\n",
    "    else:\n",
    "        accelerator.print('Updating learning rate to {}'.format(scheduler.get_last_lr()[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存模型状态字典\n",
    "model_save_path = 'time_series_predictor.pth'\n",
    "torch.save(model.state_dict(), model_save_path)\n",
    "print(f\"模型已保存到 {model_save_path}。\")\n",
    "\n",
    "# 加载模型（示例）\n",
    "# model.load_state_dict(torch.load(model_save_path))\n",
    "# model.eval()\n",
    "# print(\"模型已加载并切换到评估模式。\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TimeMM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
